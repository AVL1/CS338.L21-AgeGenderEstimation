{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### **Gender Estimation using MobileNetV1**"],"metadata":{"id":"L3EMEtCCPBI4"}},{"cell_type":"markdown","source":["### 1. Download dataset\n","- UTKFace source: https://www.kaggle.com/datasets/jangedoo/utkface-new"],"metadata":{"id":"PFZx3SDZPLMa"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T69X3oo5SGiH","outputId":"04641bbf-54f1-4a47-f0b6-807c81aa7554","executionInfo":{"status":"ok","timestamp":1665763520935,"user_tz":-420,"elapsed":69153,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}}},"source":["!gdown 1HOiaQcnemJWsYuTEHRpa3jfSFYDex7NB"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1HOiaQcnemJWsYuTEHRpa3jfSFYDex7NB\n","To: /content/UTKFace.zip\n","100% 347M/347M [01:06<00:00, 5.21MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"WCB4dhcAS0FY"},"source":["!unzip -q /content/UTKFace.zip -d data"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of images in UTKFace\n","!ls data/UTKFace | wc -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5nJdS3BPq26","executionInfo":{"status":"ok","timestamp":1665764122996,"user_tz":-420,"elapsed":433,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}},"outputId":"28c64f20-636f-45f2-aafb-62de6212d4d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23708\n"]}]},{"cell_type":"code","source":["!ls -U data/UTKFace | head -5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCgsuq0pR2rF","executionInfo":{"status":"ok","timestamp":1665764163038,"user_tz":-420,"elapsed":414,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}},"outputId":"4ae11963-e3e4-4693-f011-cdb4d9a826c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32_0_3_20170119200310531.jpg.chip.jpg\n","80_0_0_20170117173307368.jpg.chip.jpg\n","47_0_0_20170104210532204.jpg.chip.jpg\n","10_0_4_20170103212521420.jpg.chip.jpg\n","95_1_0_20170110182409918.jpg.chip.jpg\n"]}]},{"cell_type":"markdown","source":["### 2. Import libraries"],"metadata":{"id":"mD3UAJMjPia3"}},{"cell_type":"code","metadata":{"id":"kWaagvdOS6A1"},"source":["from google.colab import files\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Process dataset"],"metadata":{"id":"kxXlJZrMjmwj"}},{"cell_type":"code","metadata":{"id":"lYMAZsuUh_rf"},"source":["# Image size for mobilenetv1\n","MODEL_INPUT_IMAGE_SIZE = [128, 128]\n","\n","# Fraction of the dataset to be split test set\n","TRAIN_TEST_SPLIT = 0.3\n","\n","# Trick to one-hot encode the label.\n","y1 = tf.constant([1. ,0.], dtype='float32') # Male\n","y2 = tf.constant([0. ,1.], dtype='float32') # Female"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def parse_image(filename):\n","    # Read the image from the filename and resize it.\n","    image_raw = tf.io.read_file(filename)\n","    image = tf.image.decode_jpeg(image_raw, channels=3) \n","    #image = tf.image.resize(image, MODEL_INPUT_IMAGE_SIZE) / 255\n","    image = tf.cast(image, tf.float32)\n","    image = tf.image.resize(image, MODEL_INPUT_IMAGE_SIZE)\n","\n","    # Split the filename to get the age and the gender. \n","    # Convert the age ( str ) and the gender ( str ) to dtype float32.\n","    parts = tf.strings.split(tf.strings.split(filename, '/')[2], '_')\n","\n","    # One-hot encode the label\n","    gender = tf.strings.to_number(parts[1])\n","    gender_onehot = (gender * y2) + ((1 - gender) * y1)\n","\n","    return image, gender_onehot"],"metadata":{"id":"cbq2kQy0TfJ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List all the image files in the given directory.\n","list_ds = tf.data.Dataset.list_files('data/UTKFace/*', shuffle=True)\n","# Map `parse_image` method to all filenames.\n","dataset = list_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)"],"metadata":{"id":"q5NkfdbaTini"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMH6n58xilcc","outputId":"d7970ba1-1db8-4a5c-f518-04ae7844e935","executionInfo":{"status":"ok","timestamp":1665764982623,"user_tz":-420,"elapsed":3,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}}},"source":["# Create train and test splits of the dataset.\n","num_examples_in_test_ds = int(dataset.cardinality().numpy() * TRAIN_TEST_SPLIT)\n","\n","test_ds = dataset.take(num_examples_in_test_ds)\n","train_ds = dataset.skip(num_examples_in_test_ds)\n","\n","print('Num examples in train ds {}'.format(train_ds.cardinality()))\n","print('Num examples in test ds {}'.format(test_ds.cardinality()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num examples in train ds 16596\n","Num examples in test ds 7112\n"]}]},{"cell_type":"markdown","source":["### 4. Build and train MobileNetV1"],"metadata":{"id":"VmTnEVtxj69H"}},{"cell_type":"code","metadata":{"id":"CsLGanY6Uuuj"},"source":["BATCH_SIZE = 32\n","IMG_SIZE = (128, 128)\n","IMG_SHAPE = IMG_SIZE + (3,) # (128, 128, 3)\n","train_ds = train_ds.batch(BATCH_SIZE)\n","test_ds = test_ds.batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1ji5oChUuul","outputId":"546dfa8c-c22f-4957-82a2-d2e3b06e5d83","executionInfo":{"status":"ok","timestamp":1665765516052,"user_tz":-420,"elapsed":14126,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}}},"source":["# Create the base model from the pre-trained model MobileNet V2\n","base_model = tf.keras.applications.mobilenet.MobileNet(input_shape=IMG_SHAPE,\n","                                              include_top=False,\n","                                              weights=\"imagenet\"\n","                                              )\n","\n","base_model.trainable = False\n","\n","image_batch, label_batch = next(iter(train_ds))\n","feature_batch = base_model(image_batch)\n","print(feature_batch.shape)\n","\n","base_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_128_tf_no_top.h5\n","17225924/17225924 [==============================] - 0s 0us/step\n","(32, 4, 4, 1024)\n","Model: \"mobilenet_1.00_128\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," conv1 (Conv2D)              (None, 64, 64, 32)        864       \n","                                                                 \n"," conv1_bn (BatchNormalizatio  (None, 64, 64, 32)       128       \n"," n)                                                              \n","                                                                 \n"," conv1_relu (ReLU)           (None, 64, 64, 32)        0         \n","                                                                 \n"," conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)       288       \n","                                                                 \n"," conv_dw_1_bn (BatchNormaliz  (None, 64, 64, 32)       128       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_1_relu (ReLU)       (None, 64, 64, 32)        0         \n","                                                                 \n"," conv_pw_1 (Conv2D)          (None, 64, 64, 64)        2048      \n","                                                                 \n"," conv_pw_1_bn (BatchNormaliz  (None, 64, 64, 64)       256       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_1_relu (ReLU)       (None, 64, 64, 64)        0         \n","                                                                 \n"," conv_pad_2 (ZeroPadding2D)  (None, 65, 65, 64)        0         \n","                                                                 \n"," conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)       576       \n","                                                                 \n"," conv_dw_2_bn (BatchNormaliz  (None, 32, 32, 64)       256       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_2_relu (ReLU)       (None, 32, 32, 64)        0         \n","                                                                 \n"," conv_pw_2 (Conv2D)          (None, 32, 32, 128)       8192      \n","                                                                 \n"," conv_pw_2_bn (BatchNormaliz  (None, 32, 32, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_2_relu (ReLU)       (None, 32, 32, 128)       0         \n","                                                                 \n"," conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)      1152      \n","                                                                 \n"," conv_dw_3_bn (BatchNormaliz  (None, 32, 32, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_3_relu (ReLU)       (None, 32, 32, 128)       0         \n","                                                                 \n"," conv_pw_3 (Conv2D)          (None, 32, 32, 128)       16384     \n","                                                                 \n"," conv_pw_3_bn (BatchNormaliz  (None, 32, 32, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_3_relu (ReLU)       (None, 32, 32, 128)       0         \n","                                                                 \n"," conv_pad_4 (ZeroPadding2D)  (None, 33, 33, 128)       0         \n","                                                                 \n"," conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)      1152      \n","                                                                 \n"," conv_dw_4_bn (BatchNormaliz  (None, 16, 16, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_4_relu (ReLU)       (None, 16, 16, 128)       0         \n","                                                                 \n"," conv_pw_4 (Conv2D)          (None, 16, 16, 256)       32768     \n","                                                                 \n"," conv_pw_4_bn (BatchNormaliz  (None, 16, 16, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_4_relu (ReLU)       (None, 16, 16, 256)       0         \n","                                                                 \n"," conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)      2304      \n","                                                                 \n"," conv_dw_5_bn (BatchNormaliz  (None, 16, 16, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_5_relu (ReLU)       (None, 16, 16, 256)       0         \n","                                                                 \n"," conv_pw_5 (Conv2D)          (None, 16, 16, 256)       65536     \n","                                                                 \n"," conv_pw_5_bn (BatchNormaliz  (None, 16, 16, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_5_relu (ReLU)       (None, 16, 16, 256)       0         \n","                                                                 \n"," conv_pad_6 (ZeroPadding2D)  (None, 17, 17, 256)       0         \n","                                                                 \n"," conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)        2304      \n","                                                                 \n"," conv_dw_6_bn (BatchNormaliz  (None, 8, 8, 256)        1024      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_6_relu (ReLU)       (None, 8, 8, 256)         0         \n","                                                                 \n"," conv_pw_6 (Conv2D)          (None, 8, 8, 512)         131072    \n","                                                                 \n"," conv_pw_6_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_6_relu (ReLU)       (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)        4608      \n","                                                                 \n"," conv_dw_7_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_7_relu (ReLU)       (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_pw_7 (Conv2D)          (None, 8, 8, 512)         262144    \n","                                                                 \n"," conv_pw_7_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_7_relu (ReLU)       (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)        4608      \n","                                                                 \n"," conv_dw_8_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_8_relu (ReLU)       (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_pw_8 (Conv2D)          (None, 8, 8, 512)         262144    \n","                                                                 \n"," conv_pw_8_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_8_relu (ReLU)       (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)        4608      \n","                                                                 \n"," conv_dw_9_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_9_relu (ReLU)       (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_pw_9 (Conv2D)          (None, 8, 8, 512)         262144    \n","                                                                 \n"," conv_pw_9_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_9_relu (ReLU)       (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_dw_10 (DepthwiseConv2D  (None, 8, 8, 512)        4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_10_bn (BatchNormali  (None, 8, 8, 512)        2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_10_relu (ReLU)      (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_pw_10 (Conv2D)         (None, 8, 8, 512)         262144    \n","                                                                 \n"," conv_pw_10_bn (BatchNormali  (None, 8, 8, 512)        2048      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_10_relu (ReLU)      (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_dw_11 (DepthwiseConv2D  (None, 8, 8, 512)        4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_11_bn (BatchNormali  (None, 8, 8, 512)        2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_11_relu (ReLU)      (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_pw_11 (Conv2D)         (None, 8, 8, 512)         262144    \n","                                                                 \n"," conv_pw_11_bn (BatchNormali  (None, 8, 8, 512)        2048      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_11_relu (ReLU)      (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)        0         \n","                                                                 \n"," conv_dw_12 (DepthwiseConv2D  (None, 4, 4, 512)        4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_12_bn (BatchNormali  (None, 4, 4, 512)        2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_12_relu (ReLU)      (None, 4, 4, 512)         0         \n","                                                                 \n"," conv_pw_12 (Conv2D)         (None, 4, 4, 1024)        524288    \n","                                                                 \n"," conv_pw_12_bn (BatchNormali  (None, 4, 4, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_12_relu (ReLU)      (None, 4, 4, 1024)        0         \n","                                                                 \n"," conv_dw_13 (DepthwiseConv2D  (None, 4, 4, 1024)       9216      \n"," )                                                               \n","                                                                 \n"," conv_dw_13_bn (BatchNormali  (None, 4, 4, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_13_relu (ReLU)      (None, 4, 4, 1024)        0         \n","                                                                 \n"," conv_pw_13 (Conv2D)         (None, 4, 4, 1024)        1048576   \n","                                                                 \n"," conv_pw_13_bn (BatchNormali  (None, 4, 4, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_13_relu (ReLU)      (None, 4, 4, 1024)        0         \n","                                                                 \n","=================================================================\n","Total params: 3,228,864\n","Trainable params: 0\n","Non-trainable params: 3,228,864\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5XL1iDp7Uuuq","outputId":"0042d418-bff1-4703-f7f5-ffb4bf99cc3b","executionInfo":{"status":"ok","timestamp":1665765573666,"user_tz":-420,"elapsed":528,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}}},"source":["inputs = tf.keras.Input(shape=IMG_SHAPE)\n","x = tf.keras.applications.mobilenet.preprocess_input(inputs)\n","x = base_model(x, training=False)\n","x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","x = tf.keras.layers.Dropout(0.2)(x)\n","# outputs = tf.keras.layers.Dense(1)(x)\n","outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n","model = tf.keras.Model(inputs, outputs)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," tf.math.truediv (TFOpLambda  (None, 128, 128, 3)      0         \n"," )                                                               \n","                                                                 \n"," tf.math.subtract (TFOpLambd  (None, 128, 128, 3)      0         \n"," a)                                                              \n","                                                                 \n"," mobilenet_1.00_128 (Functio  (None, 4, 4, 1024)       3228864   \n"," nal)                                                            \n","                                                                 \n"," global_average_pooling2d (G  (None, 1024)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 2)                 2050      \n","                                                                 \n","=================================================================\n","Total params: 3,230,914\n","Trainable params: 2,050\n","Non-trainable params: 3,228,864\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"lPmG7WknY1jx"},"source":["# Init ModelCheckpoint callback\n","save_dir_ = 'mobilenetv1_gender'  \n","save_dir = save_dir_ + '/{epoch:02d}-{val_accuracy:.2f}.h5'\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( \n","    save_dir , \n","    save_best_only=True , \n","    monitor='val_accuracy' , \n","    mode='max', \n",")\n","\n","tb_log_name = 'mobilenetv1_gender'\n","# Init TensorBoard Callback\n","logdir = os.path.join( \"tb_logs\" , tb_log_name )\n","tensorboard_callback = tf.keras.callbacks.TensorBoard( logdir )\n","\n","# Init Early Stopping callback\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy' , patience=5 )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDU3P17AUuuw","outputId":"73498db2-97b5-44bc-e70a-519586318c16","executionInfo":{"status":"ok","timestamp":1665765646483,"user_tz":-420,"elapsed":35839,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}}},"source":["# warm up\n","\n","num_epochs = 1\n","learning_rate = 0.001\n","\n","model.compile( \n","    loss=tf.keras.losses.categorical_crossentropy ,\n","    optimizer = tf.keras.optimizers.Adam( learning_rate ) , \n","    metrics=[ 'accuracy' ]\n",")\n","\n","model.fit( \n","    train_ds, \n","    epochs=num_epochs,  \n","    validation_data=test_ds \n","    # callbacks=[ checkpoint_callback , tensorboard_callback , early_stopping_callback ]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["519/519 [==============================] - 35s 57ms/step - loss: 0.4366 - accuracy: 0.8010 - val_loss: 0.3336 - val_accuracy: 0.8580\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8f70292e90>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01Teocm7Uuuz","outputId":"62fdf7f0-152f-4f58-bdf3-295f9b196c9f","executionInfo":{"status":"ok","timestamp":1665767464776,"user_tz":-420,"elapsed":1794130,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}}},"source":["# fine-tuning\n","num_epochs = 30\n","learning_rate = 0.0001\n","base_model.trainable = True # unfreeze the mobilenet backbone\n","\n","model.compile( \n","    loss=tf.keras.losses.categorical_crossentropy ,\n","    optimizer = tf.keras.optimizers.Adam( learning_rate ) , \n","    metrics=[ 'accuracy' ]\n",")\n","\n","model.fit( \n","    train_ds, \n","    epochs=num_epochs,  \n","    validation_data=test_ds,\n","    callbacks=[ checkpoint_callback , tensorboard_callback , early_stopping_callback ]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","519/519 [==============================] - 60s 101ms/step - loss: 0.3671 - accuracy: 0.8433 - val_loss: 0.2429 - val_accuracy: 0.8997\n","Epoch 2/30\n","519/519 [==============================] - 56s 100ms/step - loss: 0.2408 - accuracy: 0.8987 - val_loss: 0.1955 - val_accuracy: 0.9232\n","Epoch 3/30\n","519/519 [==============================] - 56s 100ms/step - loss: 0.2095 - accuracy: 0.9120 - val_loss: 0.2677 - val_accuracy: 0.8777\n","Epoch 4/30\n","519/519 [==============================] - 55s 99ms/step - loss: 0.1859 - accuracy: 0.9243 - val_loss: 0.1977 - val_accuracy: 0.9134\n","Epoch 5/30\n","519/519 [==============================] - 56s 101ms/step - loss: 0.1766 - accuracy: 0.9293 - val_loss: 0.1518 - val_accuracy: 0.9431\n","Epoch 6/30\n","519/519 [==============================] - 55s 99ms/step - loss: 0.1611 - accuracy: 0.9346 - val_loss: 0.1267 - val_accuracy: 0.9530\n","Epoch 7/30\n","519/519 [==============================] - 55s 99ms/step - loss: 0.1487 - accuracy: 0.9418 - val_loss: 0.1187 - val_accuracy: 0.9544\n","Epoch 8/30\n","519/519 [==============================] - 57s 102ms/step - loss: 0.1407 - accuracy: 0.9449 - val_loss: 0.1442 - val_accuracy: 0.9480\n","Epoch 9/30\n","519/519 [==============================] - 57s 103ms/step - loss: 0.1325 - accuracy: 0.9513 - val_loss: 0.1084 - val_accuracy: 0.9633\n","Epoch 10/30\n","519/519 [==============================] - 57s 103ms/step - loss: 0.1303 - accuracy: 0.9511 - val_loss: 0.1089 - val_accuracy: 0.9584\n","Epoch 11/30\n","519/519 [==============================] - 58s 102ms/step - loss: 0.1248 - accuracy: 0.9519 - val_loss: 0.1023 - val_accuracy: 0.9640\n","Epoch 12/30\n","519/519 [==============================] - 58s 104ms/step - loss: 0.1130 - accuracy: 0.9575 - val_loss: 0.0901 - val_accuracy: 0.9677\n","Epoch 13/30\n","519/519 [==============================] - 59s 104ms/step - loss: 0.1055 - accuracy: 0.9617 - val_loss: 0.0776 - val_accuracy: 0.9757\n","Epoch 14/30\n","519/519 [==============================] - 59s 104ms/step - loss: 0.0997 - accuracy: 0.9650 - val_loss: 0.0779 - val_accuracy: 0.9734\n","Epoch 15/30\n","519/519 [==============================] - 58s 102ms/step - loss: 0.0942 - accuracy: 0.9681 - val_loss: 0.1130 - val_accuracy: 0.9589\n","Epoch 16/30\n","519/519 [==============================] - 57s 102ms/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 0.0805 - val_accuracy: 0.9722\n","Epoch 17/30\n","519/519 [==============================] - 56s 101ms/step - loss: 0.0840 - accuracy: 0.9725 - val_loss: 0.0556 - val_accuracy: 0.9833\n","Epoch 18/30\n","519/519 [==============================] - 56s 102ms/step - loss: 0.0837 - accuracy: 0.9729 - val_loss: 0.0602 - val_accuracy: 0.9792\n","Epoch 19/30\n","519/519 [==============================] - 57s 103ms/step - loss: 0.0779 - accuracy: 0.9745 - val_loss: 0.0578 - val_accuracy: 0.9824\n","Epoch 20/30\n","519/519 [==============================] - 57s 102ms/step - loss: 0.0723 - accuracy: 0.9766 - val_loss: 0.0805 - val_accuracy: 0.9682\n","Epoch 21/30\n","519/519 [==============================] - 58s 103ms/step - loss: 0.0651 - accuracy: 0.9800 - val_loss: 0.0703 - val_accuracy: 0.9751\n","Epoch 22/30\n","519/519 [==============================] - 58s 103ms/step - loss: 0.0635 - accuracy: 0.9797 - val_loss: 0.0441 - val_accuracy: 0.9876\n","Epoch 23/30\n","519/519 [==============================] - 57s 102ms/step - loss: 0.0607 - accuracy: 0.9822 - val_loss: 0.0455 - val_accuracy: 0.9858\n","Epoch 24/30\n","519/519 [==============================] - 58s 104ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 0.1146 - val_accuracy: 0.9589\n","Epoch 25/30\n","519/519 [==============================] - 58s 103ms/step - loss: 0.0608 - accuracy: 0.9814 - val_loss: 0.0476 - val_accuracy: 0.9866\n","Epoch 26/30\n","519/519 [==============================] - 58s 104ms/step - loss: 0.0493 - accuracy: 0.9852 - val_loss: 0.0344 - val_accuracy: 0.9902\n","Epoch 27/30\n","519/519 [==============================] - 59s 105ms/step - loss: 0.0470 - accuracy: 0.9867 - val_loss: 0.0503 - val_accuracy: 0.9824\n","Epoch 28/30\n","519/519 [==============================] - 58s 103ms/step - loss: 0.0457 - accuracy: 0.9873 - val_loss: 0.0450 - val_accuracy: 0.9855\n","Epoch 29/30\n","519/519 [==============================] - 58s 103ms/step - loss: 0.0465 - accuracy: 0.9872 - val_loss: 0.0262 - val_accuracy: 0.9931\n","Epoch 30/30\n","519/519 [==============================] - 58s 103ms/step - loss: 0.0461 - accuracy: 0.9863 - val_loss: 0.0433 - val_accuracy: 0.9871\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8f00600dd0>"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["### 6. Save trained models"],"metadata":{"id":"Bu5XnuyukEns"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aj_DkUAPrqTB","outputId":"0f9fb801-621e-48bb-e374-0fa000705adc","executionInfo":{"status":"ok","timestamp":1665767867708,"user_tz":-420,"elapsed":414,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}}},"source":["!ls mobilenetv1_gender/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["01-0.90.h5  06-0.95.h5\t11-0.96.h5  17-0.98.h5\t29-0.99.h5\n","02-0.92.h5  07-0.95.h5\t12-0.97.h5  22-0.99.h5\n","05-0.94.h5  09-0.96.h5\t13-0.98.h5  26-0.99.h5\n"]}]},{"cell_type":"code","source":["# Save trained models to drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5GKb_CDf1sL","executionInfo":{"status":"ok","timestamp":1665767817870,"user_tz":-420,"elapsed":18367,"user":{"displayName":"Trung Anh Tran","userId":"12549072950214368908"}},"outputId":"091aee2b-446d-442b-e832-c444805e619d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp mobilenetv1_gender /content/drive/MyDrive/AgeGenderEstimation/"],"metadata":{"id":"vBmvTu0lf-zD"},"execution_count":null,"outputs":[]}]}